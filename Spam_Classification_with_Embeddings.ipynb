{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+Xo8Is9g9Wwe6wICl7mVG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshvinVignesh/Spam-Classification-with-Embeddings-and-LSTM/blob/main/Spam_Classification_with_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "crg9msP_LWL9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"Spam-Classification.csv\")\n",
        "data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "apJhqOVC--kZ",
        "outputId": "5d55e45a-f8b4-46a6-b92a-af9e1a36fc37"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  CLASS                                                SMS\n",
              "0   ham   said kiss, kiss, i can't do the sound effects...\n",
              "1   ham      &lt;#&gt; ISH MINUTES WAS 5 MINUTES AGO. WTF.\n",
              "2  spam  (Bank of Granite issues Strong-Buy) EXPLOSIVE ...\n",
              "3  spam  * FREE* POLYPHONIC RINGTONE Text SUPER to 8713...\n",
              "4  spam  **FREE MESSAGE**Thanks for using the Auction S..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-823bd2f5-29a1-4043-aa8c-0c7cdc7e891b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CLASS</th>\n",
              "      <th>SMS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>said kiss, kiss, i can't do the sound effects...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>&amp;lt;#&amp;gt; ISH MINUTES WAS 5 MINUTES AGO. WTF.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>(Bank of Granite issues Strong-Buy) EXPLOSIVE ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>spam</td>\n",
              "      <td>* FREE* POLYPHONIC RINGTONE Text SUPER to 8713...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>spam</td>\n",
              "      <td>**FREE MESSAGE**Thanks for using the Auction S...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-823bd2f5-29a1-4043-aa8c-0c7cdc7e891b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-823bd2f5-29a1-4043-aa8c-0c7cdc7e891b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-823bd2f5-29a1-4043-aa8c-0c7cdc7e891b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0nNRzywCxW1",
        "outputId": "06bb2252-2775-4212-b167-80a86271daea"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.count of      CLASS                                                SMS\n",
              "0      ham   said kiss, kiss, i can't do the sound effects...\n",
              "1      ham      &lt;#&gt; ISH MINUTES WAS 5 MINUTES AGO. WTF.\n",
              "2     spam  (Bank of Granite issues Strong-Buy) EXPLOSIVE ...\n",
              "3     spam  * FREE* POLYPHONIC RINGTONE Text SUPER to 8713...\n",
              "4     spam  **FREE MESSAGE**Thanks for using the Auction S...\n",
              "...    ...                                                ...\n",
              "1495   ham       Yup, no need. I'll jus wait 4 e rain 2 stop.\n",
              "1496   ham  Yup... From what i remb... I think should be c...\n",
              "1497   ham                           Yup... How Ã¼ noe leh...\n",
              "1498   ham  Yup... Ok i go home look at the timings then i...\n",
              "1499  spam  <Forwarded from 21870000>Hi - this is your Mai...\n",
              "\n",
              "[1500 rows x 2 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target = data[\"CLASS\"]\n",
        "sms = data[\"SMS\"]\n",
        "target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoY2RDX6_R5A",
        "outputId": "a9a1477f-e64c-44c0-d59b-8da68bf85068"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        ham\n",
              "1        ham\n",
              "2       spam\n",
              "3       spam\n",
              "4       spam\n",
              "        ... \n",
              "1495     ham\n",
              "1496     ham\n",
              "1497     ham\n",
              "1498     ham\n",
              "1499    spam\n",
              "Name: CLASS, Length: 1500, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn import preprocessing\n"
      ],
      "metadata": {
        "id": "-YCYLR1D_6zj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "spam_classes = label_encoder.fit_transform(target)\n",
        "\n",
        "#Convert target to one-hot encoding vector\n",
        "spam_classes = tf.keras.utils.to_categorical(spam_classes,2)\n"
      ],
      "metadata": {
        "id": "Tj0B2KtSANNM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "     "
      ],
      "metadata": {
        "id": "2gaNCoFEEDXt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOCABULARY_WORDS = 10000\n",
        "MAX_SEQUNCE_LENGTH = 100"
      ],
      "metadata": {
        "id": "udWzAX0MHv4g"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This step builds a vocabulary of unique words from the SMS list and assigns a unique ID (integer) to each word."
      ],
      "metadata": {
        "id": "-Ltba3vjJN_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spam_tokenizer = Tokenizer(num_words=VOCABULARY_WORDS)\n",
        "spam_tokenizer.fit_on_texts(sms)"
      ],
      "metadata": {
        "id": "FloQ3Yc9ILS2"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first print statement displays the total number of unique tokens (words) found in the spam messages. The second print statement demonstrates how to retrieve the token ID for a specific word (in this case, \"me\")."
      ],
      "metadata": {
        "id": "OF2QJd86KSgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total unique tokens found: \", len(spam_tokenizer.word_index))\n",
        "print(\"Example token ID for word \\\"said\\\":\", spam_tokenizer.word_index.get(\"said\"))\n",
        "print(\"Example token ID for word \\\"kiss\\\":\", spam_tokenizer.word_index.get(\"kiss\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9z3cwA3JPj9",
        "outputId": "c68965ed-f45d-4db2-d467-500967319b6d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique tokens found:  4688\n",
            "Example token ID for word \"said\": 260\n",
            "Example token ID for word \"kiss\": 921\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The blow code converts each sentence in the spam_messages list into a sequence of token IDs based on the tokenizer's vocabulary."
      ],
      "metadata": {
        "id": "izivc96dLRD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spam_sequences = spam_tokenizer.texts_to_sequences(sms)\n"
      ],
      "metadata": {
        "id": "lSIaQ1vZLGei"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pad_sequences function is used to ensure that all sequences have the same length. Sequences shorter than the specified maxlen are padded with zeros at the beginning, while longer sequences are truncated. The resulting sequences will have a fixed length of MAX_SEQUENCE_LENGTH."
      ],
      "metadata": {
        "id": "SYxQLuBhLwNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spam_padded = pad_sequences(spam_sequences, maxlen=MAX_SEQUNCE_LENGTH)"
      ],
      "metadata": {
        "id": "4NWNOeXGLx9N"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTotal sequences found : \", len(spam_padded))\n",
        "print(\"Example Sequence for sentence : \", sms[0] )\n",
        "print(spam_padded[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ky-4rPotMGpT",
        "outputId": "53af9e08-7328-492b-8d5b-565977e3bea6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total sequences found :  1500\n",
            "Example Sequence for sentence :   said kiss, kiss, i can't do the sound effects! He is a gorgeous man isn't he! Kind of person who needs a smile to brighten his day! \n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0  260  921  921    4  430   55    6 1488 2294  148   10\n",
            "    3 1489  464 1143  148  922   19  514   77 1144    3  515    1 2295\n",
            "  397   89]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "7056rH7QMOlB"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(spam_padded,spam_classes,test_size=0.2)"
      ],
      "metadata": {
        "id": "4wc9ZDi9MPjt"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Building the embeddding matrix using GLOVE dictionary"
      ],
      "metadata": {
        "id": "0ytpwPhgMt6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#Read pretrained embeddings into a dictionary\n",
        "glove_dict = {} \n",
        "\n",
        "#Loading a 50 feature (dimension) embedding with 6 billion words\n",
        "with open('glove.6B.50d.txt', \"r\", encoding=\"utf8\") as glove_file:     \n",
        "    for line in glove_file:\n",
        "        \n",
        "        emb_line = line.split()      \n",
        "        emb_token = emb_line[0]         \n",
        "        emb_vector = np.array(emb_line[1:], dtype=np.float32)\n",
        "        \n",
        "        if emb_vector.shape[0] == 50:    \n",
        "            glove_dict[emb_token] = emb_vector\n",
        "\n"
      ],
      "metadata": {
        "id": "wmmpOuFVMsiP"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_len = len(spam_tokenizer.word_index) + 1\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_len, 50))\n",
        "\n",
        "for word, id in spam_tokenizer.word_index.items():  \n",
        "    try:\n",
        "        embedding_vector = glove_dict.get(word) \n",
        "        if embedding_vector is not None:         \n",
        "            embedding_matrix[id] = embedding_vector\n",
        "    except:\n",
        "        pass"
      ],
      "metadata": {
        "id": "1uXRFc-gM8Aj"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from keras.layers import LSTM,Dense"
      ],
      "metadata": {
        "id": "v-DvNyo2N1Pb"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_of_output= 2\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(keras.layers.Embedding(vocab_len,\n",
        "                                 50,   #50: The size of the embedding vector. Each word will be represented by a dense vector of length 50 in the embedding space.\n",
        "                                 name=\"Embedding-Layer\",\n",
        "                                 weights=[embedding_matrix],\n",
        "                                 input_length=MAX_SEQUNCE_LENGTH,\n",
        "                                 trainable=True))\n",
        "\n",
        "#Add LSTM Layer\n",
        "model.add(LSTM(256))\n",
        "model.add(keras.layers.Flatten())\n",
        "\n",
        "model.add(keras.layers.Dense(no_of_output,\n",
        "                             name='Output-Layer',\n",
        "                             activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "pv4nrRcrQzRR"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKY7EcBPQ6o3",
        "outputId": "d2748524-fd3f-41f4-c7be-2741f077d045"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Embedding-Layer (Embedding)  (None, 100, 50)          234450    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 256)               314368    \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " Output-Layer (Dense)        (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 549,332\n",
            "Trainable params: 549,332\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VERBOSE=1\n",
        "\n",
        "#Setup Hyper Parameters for training\n",
        "BATCH_SIZE=256\n",
        "EPOCHS=10\n",
        "VALIDATION_SPLIT=0.2\n",
        "\n",
        "print(\"\\nTraining Progress:\\n------------------------------------\")\n",
        "\n",
        "history=model.fit(X_train,\n",
        "          Y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=VERBOSE,\n",
        "          validation_split=VALIDATION_SPLIT)\n",
        "\n",
        "print(\"\\nEvaluation against Test Dataset :\\n------------------------------------\")\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLLGHzryTKjz",
        "outputId": "23c83c5b-211f-4562-f265-ed0307601d06"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Progress:\n",
            "------------------------------------\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 9s 2s/step - loss: 0.6188 - accuracy: 0.5906 - val_loss: 0.4319 - val_accuracy: 0.8583\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.4071 - accuracy: 0.8302 - val_loss: 0.2739 - val_accuracy: 0.8917\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 6s 1s/step - loss: 0.2197 - accuracy: 0.9167 - val_loss: 0.2596 - val_accuracy: 0.9000\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 6s 2s/step - loss: 0.3023 - accuracy: 0.8844 - val_loss: 0.2603 - val_accuracy: 0.9042\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.1856 - accuracy: 0.9365 - val_loss: 0.2131 - val_accuracy: 0.9125\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.2246 - accuracy: 0.9229 - val_loss: 0.2235 - val_accuracy: 0.9167\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 6s 1s/step - loss: 0.1553 - accuracy: 0.9458 - val_loss: 0.2556 - val_accuracy: 0.9042\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.1570 - accuracy: 0.9406 - val_loss: 0.2261 - val_accuracy: 0.9167\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 6s 2s/step - loss: 0.1282 - accuracy: 0.9469 - val_loss: 0.3561 - val_accuracy: 0.8792\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.1462 - accuracy: 0.9417 - val_loss: 0.2403 - val_accuracy: 0.9125\n",
            "\n",
            "Evaluation against Test Dataset :\n",
            "------------------------------------\n",
            "10/10 [==============================] - 1s 85ms/step - loss: 0.1551 - accuracy: 0.9467\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.15506385266780853, 0.9466666579246521]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    }
  ]
}